---
layout: presentation.njk
title: "Rapid Prototyping of a Positioning System"
presentation_title: "<span style='font-size: 80%'>Rapid Prototyping of a Positioning System</span>"
subtitle: "Using the OpenHPS Framework"
author: Maxim Van de Wynckel
logo: true
header_logo: /images/misc/openhps-logo.svg
affiliation: Web & Information Systems Engineering Lab</br>Vrije Universiteit Brussel
---

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Positioning System
            *"A positioning system is a mechanism for determining the position of an object in space."*\
            [<small>*- Wikipedia (2022)*</small>](https://en.wikipedia.org/wiki/Positioning_system)
        {% endmarkdown %}
    </section>
    <section data-markdown data-auto-animate data-timing="20">
    {% markdown %}
        ## Positioning System
        *"A positioning system is a mechanism for determining the position of an **object** in **space**."*\
        [<small>*- Wikipedia (2022)*</small>](https://en.wikipedia.org/wiki/Positioning_system)

        **Object**\
        What are you tracking? A person, an asset or a phone?

        **Space**\
        Outdoor, indoor, on a table or on a game board?
    {% endmarkdown %}
</section>

</section>

<section data-markdown data-auto-animate data-timing="20">
    {% markdown %}
        ## Use Cases
        - Navigation\
            *Navigate a person from point A to point B*
        - Tracking\
            *Asset tracking, customer tracking, tracking items on a table*
        - Location Awareness\
            *Trigger an action whenever a specific person is in a room*
        - Mapping\
            *Geospatial mapping of an environment*
    {% endmarkdown %}
    <aside class="notes">
    
    </aside>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Technologies
            *Technologies used to obtain sensor data for positioning*
            - Camera (Sterescopic/Monocular/Omnidirectional)
            - Bluetooth Beacons
            - WLAN Access Points
            - Ultrawideband Beacons
            - LIDAR
            - ...
        {% endmarkdown %}
    </section>
</section>


<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Algorithms
            *Algorithms used to process sensor data*
            - Lateration
            - Proximity positioning
            - Fingerprinting
            - Computer vision
            - Dead reckoning
            - Sensor fusion
            - ...
        {% endmarkdown %}
    </section>
</section>

<section data-markdown data-auto-animate data-timing="20">
    {% markdown %}
        ## Established Open Source Solutions
        - AnyPlace *[https://anyplace.cs.ucy.ac.cy/](https://anyplace.cs.ucy.ac.cy/)*
        - FIND *[https://github.com/schollz/find3](https://github.com/schollz/find3)*
        - IndoorLocation *[https://github.com/IndoorLocation](https://github.com/IndoorLocation)*
    {% endmarkdown %}
    <aside class="notes">
    
    </aside>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## What is OpenHPS?
            ### An Open Source Hybrid Positioning System
        {% endmarkdown %}
        <img width="67%" class="shadow" src="../ipin2021/images/openhps-site.png"/>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## What is OpenHPS?
            ### An Open Source Hybrid Positioning System
            - Any technology
            - Any algorithm
            - Various use cases
            - Flexibile processing and output
                - Accuracy over battery consumption, reliability, ...
            - Aimed towards developers with knowledge on positioning techniques
        {% endmarkdown %}
        <aside class="notes">
        With OpenHPS we aim to offer a framework for developers and researchers that
        can support a variety of positioning technologies, algorithms and uses cases that are not just
        limited to indoor positioning. We also aim to offer a lot of flexibility in the outcome of the position,
        weither it is a developer wishing to offer the most accurate position, power optimized solution or
        simply a reliable system that can rougly (but reliably) indicate weither or not you are in a specific room.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="25">
        <h2 data-id="title-processnetworkdesign">Process Network Design</h2>
        <img width="90%" src="../ipin2021/images/architecture.svg"/>
        <aside class="notes">
        When creating a positioning system, you obtain sensor data from multiple different sensors. You process the data until at some stage in your processing
        you merge the sensor data to obtain a position that you can show to your user.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="30%" src="../ipin2021/images/architecture.svg"/>
        <img height="45%" data-id="architecture-graph" src="../ipin2021/images/architecture2.svg"/>
        <aside class="notes">
        OpenHPS focuses on this method of developing a positioning system by allowing the creation of a process network with graph topology. 
        We identify source nodes that provide data, processing nodes that process this data and finally sink nodes that store or display this data. 
        We call this complete process network from source to sink a positioning model.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="35">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="70%" style="margin-top: 1em" data-id="architecture-graph" src="../ipin2021/images/architecture3.svg"/>
        <aside class="notes">
        On top of this, every node in our process network has access to a range of 'Services' that either manage the persistent storage of data that is being handled or
        handle background processing of information that is already pushed through the network. Each service can be added to multiple positioning models, allowing data
        exchange between the calibration part of a process network and the actual online stage used on a production ready system.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        <h2 data-id="title-modularity">Modularity</h2>
        <img width="100%" style="margin-top: 2em" src="../ipin2021/images/stack.svg"/>
        <aside class="notes">
        By creating this process network design with shared services we allow for a very modular ecosystem where individual nodes or services
        can be reused throughout multiple different packages. Our core component offers the main concepts
        needed to design a process network for processing sensor data to an output position while other components
        handle the communication, data storage or add additional algorithms.
        </aside>
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Current State
            **Communication**\
            Socket, MQTT, REST API

            **Data Storage**\
            MongoDB, LocalStorage, RDF

            **Positioning Algorithms**\
            IMU, fingerprinting, RF, OpenVSLAM

            **Abstractions**\
            Geospatial, location-based services

            **Mobile (sensor source)**\
            React-Native, NativeScript
        {% endmarkdown %}
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="30">
        {% markdown %}
            ## Data Processing
        {% endmarkdown %}
        <img height="80%" src="../ipin2021/images/datatypes.svg" class="logo">
        <aside class="notes">
        The data that we process in our process network is an important aspect of the core of OpenHPS.
        We have knowledge, raw data and processed data. Knowledge is everything that we know - such as sensors, radio transmitters
        or building layouts. Raw data is unprocessed data that we want to process, such as individual video or image frames, unfiltered
        accelerometer data. And finally, we have the processed data that will eventually become knowledge.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## DataObject
            
        {% endmarkdown %}
        <img height="75%" src="../ipin2021/images/dataobject.svg"/>
        <aside class="notes">
        We represent this knowledge and processed data under the term dataobject.

        A data object is any spatial entity that is relevant for the positioning of other data objects. A data object can be considered
        a camera object tracking another object - or it can be a phone that is responsible itself for
        the data collection.

        Each data object can have a hierarchical relation with other objects.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        {% markdown %}
            ## Absolute and Relative Positions
            **Absolute**
            - 2D, 3D, Geographical, ...

            **Relative**
            - Distance, angle, velocity, ...
            - Relative to another *object*
        {% endmarkdown %}
        <aside class="notes">
        These spatial objects can have an absolute or relative position. An absolute position
        represents a fixed position in space. We support 2D, 3D and geographical positions.

        Relative positions are relative to another object and can be expressed in 
        distance, angle, velocity or a more abstract RSS.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-visibility="hidden">
        {% markdown %}
            ## ReferenceSpace
            *An absolute position can be relative to a reference space.*
        {% endmarkdown %}
        <img width="70%" src="../ipin2021/images/referencespace.svg"/>
        <aside class="notes">
        Reference spaces are data objects that represent a transformation of a position. When setting the position or orientation of an object
        you can optionally specify the reference space.

        Similar to data objects, reference spaces can have a hierarchical relation with other objects.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="80">
        <h2 data-id="title-dataframe">DataFrame</h2>
        <img height="75%" src="../ipin2021/images/dataframe_single.svg"/>
        <aside class="notes">
        In order to contain our processed data with our raw data, we create a new Data frame.

        Data frames are individual captured moments of sensor data processed in the positioning system. They are the
        enveloppes transmitted through the process network and are usually created
        by a source object and can contain a set of relevant objects or raw sensor data that are added or modified by nodes in our network

        In this example image we have a video frame that is captured by a camera object. It contains the actual image
        of that frame and a set of objects that were detected inside this frame.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-visibility="uncounted" data-timing="0">
        <h2 data-id="title-dataframe">DataFrame ...</h2>
        {% markdown %}
            ### Pushing Data

        {% endmarkdown %}
        <img width="100%" src="../ipin2021/images/nodes-push.svg"/>
        <aside class="notes">
        [OPTIONAL SLIDE] 
        </aside>
    </section>
    <section data-markdown data-auto-animate data-visibility="uncounted" data-timing="0">
        <h2 data-id="title-dataframe">DataFrame ...</h2>
        {% markdown %}
            ### Pulling Data

        {% endmarkdown %}
        <img width="100%" src="../ipin2021/images/nodes-pull.svg"/>
        <aside class="notes">
        [OPTIONAL SLIDE] 
        </aside>
    </section>
    <section data-markdown data-auto-animate data-visibility="uncounted" data-timing="0">
        <h2 data-id="title-dataframe">DataFrame ...</h2>
        {% markdown %}
            ### Pushing Error

        {% endmarkdown %}
        <img width="100%" src="../ipin2021/images/nodes-push-error.svg"/>
        <aside class="notes">
        [OPTIONAL SLIDE] Errors can of course occur in the process network. When this happens, the push is rejected instead of resolved - and the
        last node that performed the failed push will emit an error that will propagate upstream so the upstream nodes
        are aware of the error. It is down to the developer to decide how these errors are handled.
        </aside>
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Contributing
            - Positioning algorithms
            - Process network communication
            - Bindings to other systems
            - (UI) abstractions
            - Documentation and examples
        {% endmarkdown %}
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Example
            *You want to develop a cheap method of tracking small boxes in a lab.*
            ![](images/20220106_154330.jpg)
        {% endmarkdown %}
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Example
            *You want to develop a cheap method of tracking small boxes in a lab.*
            ### Design considerations
            - Boxes can be relatively small
            - Hardware should not be expensive
            - Position in a lab should be relatively accurate
            - Infrastructure in the lab can change
        {% endmarkdown %}
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Example: Implementation
            - Transmitting Bluetooth beacons in each box
            - Bluetooth receivers around the room with WiFi connectivity (ESP32)
            - Central server (Raspberry Pi) for keeping track of the boxes
            - API endpoint in Raspberry Pi
        {% endmarkdown %}
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Example: Implementation
            ### Receivers and Transmitters
            - ESP32 with Espruino firmware as plugged-in receivers
			- iTAG Bluetooth key trackers as tracked devices
        {% endmarkdown %}
        <img height="50%" src="images/20220106_165351.png">
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## Example: Implementationd
            ### Positioning model

        {% endmarkdown %}
    </section>
</section>

<section data-markdown data-auto-animate data-timing="30">
    <style>
    .qr-image {
        width: 200px;
        height: 200px;
    }
    </style>
    {% markdown %}
        ## Contributions and Conclusions
        - 
    {% endmarkdown %}
    <div class="row" style="position: absolute; bottom: 7vh;">
        <div class="col-3">
            <img class="qr-image" src="../ipin2021/images/qr-code.svg"/>
        </div>
        <div class="col-7">
            {% markdown %}
            \
            *Visit [https://openhps.org](https://openhps.org) for additional resources,
            documentation, source code and more!*
            {% endmarkdown %}
        </div>
    </div>
</section>