---
layout: presentation.njk
title: Next Generation User Interfaces - Indoor Positioning and Location Awareness
presentation_title: Next Generation User Interfaces</br><small>Indoor Positioning and Location Awareness</small>
author: Maxim Van de Wynckel
logo: true
width: 1280
height: 720
header_logo: /images/misc/openhps-logo.svg
---
{% decktape title, page %}

<section data-markdown>
    {% markdown %}
        ## Indoor Positioning System
        
        "*An indoor positioning system (IPS) is a network of devices used to locate people or objects where GPS and other satellite technologies lack precision or fail entirely, such as inside multistory buildings, airports, alleys, parking garages, and underground locations.*"
        
        [<small>*- Wikipedia (2022)*</small>](https://en.wikipedia.org/wiki/Indoor_positioning_system)\
        [<small>*- (image) Bonkers.io (2018)*</small>](https://www.bonkers.io/assets/papers/Bonkers_ICO_WhitePaper_1.0.7.pdf)
    {% endmarkdown %}
    <img height="60%" style="position: absolute; right: 0; top: 200px;" src="images/ips.png">
</section>
<section>
    <section data-markdown>
        {% markdown %}
            ## Location Awareness
            
            "*Location awareness refers to devices that can passively or actively determine their location.*"
            
            [<small>*- Wikipedia (2022)*</small>](https://en.wikipedia.org/wiki/Location_awareness)
        {% endmarkdown %}
    </section>
    <section data-markdown>
        {% markdown %}
            ## Contextual Location Awareness
            Using the location of a person or asset as contextual information for **implicit human-computer interaction**.

            *NOTE: You will see implicit human-computer interaction in a later lecture*
        {% endmarkdown %}
    </section>
</section>
<section>
    <section data-markdown data-auto-animate class="left">
        {% markdown %}
            ## Use Cases
            ### Indoor Navigation
            <img src="./images/indoor-navigation.png" width="50%"></br>
            [<small>*- Gatwick Airport Limited (2017)*</small>](http://www.mediacentre.gatwickairport.com/press-releases/2017/17_05_25_beacons.aspx)
        {% endmarkdown %}
    </section>
    <section data-markdown data-auto-animate class="left">
        {% markdown %}
            ## Use Cases ...
            ### Asset Tracking
            - Track the location of expensive items
            - Material resource planning
            - Personnel tracking


        {% endmarkdown %}
            <div class="row">
                <div class="col-5">
                    <img src="./images/apple-airtag.jpg" width="100%"></br>
                </div>
                <div class="col-3">
                    <img src="./images/asset-tracking.png" width="100%"></br>
                </div>
                <div class="col-3">
                    {% markdown %}
                        [<small>*- LetsGoDigital (2021)*</small>](https://nl.letsgodigital.org/accessoires/apple-airtag/)\
                        [<small>*- Favendo (2022)*</small>](https://www.favendo.com/asset-tracking/asset-tracking-software-by-favendo)
                    {% endmarkdown %}
                </div>
            </div>
    </section>
    <section data-markdown data-auto-animate class="left">
        {% markdown %}
            ## Use Cases ...
            ### Implicit Interaction
            - Home automation
            - Resource assigning
            - Machine learning recommendations
        {% endmarkdown %}
    </section>
    <section data-markdown data-auto-animate>
        {% markdown %}
            ## Use Cases ...
            ### Autonomous Robots
            <img src="./images/roborock.jpg" width="45%"></br>
            [<small>*- Jim Martin (2019)*</small>](https://www.techadvisor.com/review/roborock-s6-3696730/)
        {% endmarkdown %}
    </section>
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Positioning Technologies
        - RF-based <small>(Wi-Fi, Bluetooth, UWB)</small>
        - Sound-based <small>(Ultrasound beacons, ambient noise)</small>
        - Camera-based <small>(VSLAM, MTMC, VLC)</small>
        - Inertial Measurement Unit (IMU-based) <small>(acceleration, velocity, geomagnetic)</small>
        - *Many more ...*
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Positioning Algorithms
        - Fingerprinting <small>(k-NN, affinity propagation, clustering, ...)</small>
        - Mathematical <small>(triangulation, multilateration, ...)</small>
        - Dead reckoning
        - Sensor fusion <small>(complementary filters, probabilistic, ...)</small>
        - Cartographing
        - *Many more ...*
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Bluetooth beacons
        A small (battery powered) device that sends out a BLE advertisement in a fixed interval. The received signal
        strength is used to esimate the linear distance.

        **Algorithms:**
        - Fingerprinting
        - Multilateration, Cell-Identification
    {% endmarkdown %}
    <img src="./images/beacon.png" width="45%"></br>
</section>
<section>
    <section data-markdown class="left">
        {% markdown %}
            ## Multilateration (>3 transmitters)
            <img src="./images/multilateration-1.svg" width="45%"></br>
            [<small>*- Van de Wynckel, Maxim (2019)*</small>](https://researchportal.vub.be/en/studentTheses/indoor-navigation-by-centralized-tracking)
        {% endmarkdown %}
    </section>
    <section data-markdown class="left">
        {% markdown %}
            ## Multilateration (2 transmitters)
            <img src="./images/multilateration-2.svg" width="80%"></br>
            [<small>*- Van de Wynckel, Maxim (2019)*</small>](https://researchportal.vub.be/en/studentTheses/indoor-navigation-by-centralized-tracking)
        {% endmarkdown %}
    </section>
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Cell-Identification (1 transmitter)
        <img src="./images/cell-id-multilateration.svg" width="50%"></br>
        [<small>*- Van de Wynckel, Maxim (2019)*</small>](https://researchportal.vub.be/en/studentTheses/indoor-navigation-by-centralized-tracking)
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Ultra wideband
        A small (battery powered) device that sends out an RF signal over a large band (6 - 8 GHz), allowing the use of Time of Flight (ToF)
        for determining the distance to centimeter precision. More power consumption than BLE.

        **Algorithms:**
        - Multilateration
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Wi-Fi access points
        Existing Wi-Fi infrastructure to predict the position based on the signal strength or Time of Flight (ToF) on supported access points.

        **Algorithms:**
        - Fingerprinting
        - Multilateration
    {% endmarkdown %}
</section>
<section>
    <section data-markdown class="left">
        {% markdown %}
            ## Fingerprinting
            <img src="../ipin2021/images/datapoints.svg" width="50%"></br>
            [<small>*- Van de Wynckel, Maxim \& Signer, Beat (2021)*</small>](https://researchportal.vub.be/en/publications/indoor-positioning-using-the-openhps-framework)
        {% endmarkdown %}
    </section>
    <section data-markdown class="left">
        {% markdown %}
            ## Fingerprinting ...
            <img src="./images/dataset.png" width="80%"></br>
            [<small>*- Van de Wynckel, Maxim \& Signer, Beat (2021)*</small>](https://researchportal.vub.be/en/publications/indoor-positioning-using-the-openhps-framework)
        {% endmarkdown %}
    </section>
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Inertial Measurement Unit (IMU sensor)
        Accelerometer, gyroscope and magnetometer to determine the orientation, linear
        and angular velocity. Optionally can contain a barometer.

        **Algorithms:**
        - Dead reckoning (raw, pedometer)
        - Geomagnetic fingerprinting
    {% endmarkdown %}
    <img src="images/imu.jpg" width="40%">
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Dead Reckoning
        <img src="./images/deadreckoning.png" width="55%"></br>
        [<small>*- OXTS (2022)*</small>](https://www.oxts.com/dead-reckoning/)
    {% endmarkdown %}
</section>
<section>
    <section data-markdown data-auto-animate data-timing="20">
        {% markdown %}
            ## What is OpenHPS?
            ### An Open Source Hybrid Positioning System
        {% endmarkdown %}
        <img width="67%" class="shadow" src="../ipin2021/images/openhps-site.png"/>
        <aside class="notes">
        In this paper we introduced OpenHPS and its use within the domain of indoor positioning.

        OpenHPS is an open source hybrid positioning system developed in TypeScript that can run both on a server, 
        embedded device, smartphone or even the browser.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## OpenHPS
            ### An Open Source Hybrid Positioning System
            - Any technology
            - Any algorithm
            - Various use cases
            - Flexible processing and output
                - Prefer accuracy over battery consumption, reliability, ...
            - Aimed towards developers and researchers
        {% endmarkdown %}
        <aside class="notes">
        With OpenHPS we aim to offer a framework for developers and researchers that
        can support a variety of positioning technologies, algorithms and uses cases. We also aim to offer a lot of flexibility in the outcome of the position,
        weither it is a developer wishing to offer the most accurate position, power optimized solution or
        simply a reliable system that can rougly (but reliably) indicate weither or not you are in a specific room.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="25">
        <h2 data-id="title-processnetworkdesign">Process Network Design</h2>
        <img width="90%" src="../fosdem2022/images/architecture.svg"/>
        <aside class="notes">
        When creating a positioning system, you obtain sensor data from multiple different sensors. You process the data until at some stage in your processing
        you merge the sensor data to obtain a position that you can show to your user.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="30%" src="../fosdem2022/images/architecture.svg"/>
        <img height="45%" data-id="architecture-graph" src="../fosdem2022/images/architecture2.svg"/>
        <aside class="notes">
        OpenHPS focuses on this method of developing a positioning system by allowing the creation of a process network with graph topology. 
        We identify source nodes that provide data, processing nodes that process this data and finally sink nodes that store or display this data. 
        We call this complete process network from source to sink a positioning model. 
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="30%" src="../fosdem2022/images/architecture.svg"/>
        <img height="45%" data-id="architecture-graph" src="../fosdem2022/images/architecture2_source.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="30%" src="../fosdem2022/images/architecture.svg"/>
        <img height="45%" data-id="architecture-graph" src="../fosdem2022/images/architecture2_processing.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="30%" src="../fosdem2022/images/architecture.svg"/>
        <img height="45%" data-id="architecture-graph" src="../fosdem2022/images/architecture2_sink.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="35">
        <h2 data-id="title-processnetworkdesign">Process Network Design ...</h2>
        <img height="70%" style="margin-top: 1em" data-id="architecture-graph" src="../fosdem2022/images/architecture3.svg"/>
        <aside class="notes">
        On top of this, every node in our process network has access to a range of 'Services' that either manage the persistent storage of data that is being handled or
        handle background processing of information that is already pushed through the network. Each service can be added to multiple positioning models, allowing data
        exchange between the calibration part of a process network and the actual online stage used on a production ready system.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        <h2 data-id="title-modularity">Modularity</h2>
        <img width="100%" data-id="stack" style="margin-top: 2em" src="../ipin2021/images/stack.svg"/>
        <aside class="notes">
        By creating this process network design with shared services we allow for a very modular ecosystem where individual nodes or services
        can be reused throughout multiple different packages. Our core component offers the main concepts
        needed to design a process network for processing sensor data to an output position while other components
        handle the communication, data storage or add additional algorithms.
        </aside>
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="20">
        <h2 data-id="title-modularity">Modularity ...</h2>
        <img width="90%" style="margin-top: -0.3em" data-id="stack-examples" src="../fosdem2022/images/stack_examples.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        <h2 data-id="title-modularity">Modularity ...</h2>
        <img width="90%" style="margin-top: -0.3em" data-id="stack-examples" src="../fosdem2022/images/stack_examples_1.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        <h2 data-id="title-modularity">Modularity ...</h2>
        <img width="90%" style="margin-top: -0.3em" data-id="stack-examples" src="../fosdem2022/images/stack_examples_2.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        <h2 data-id="title-modularity">Modularity ...</h2>
        <img width="90%" style="margin-top: -0.3em" data-id="stack-examples" src="../fosdem2022/images/stack_examples_3.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="20">
        <h2 data-id="title-modularity">Modularity ...</h2>
        <img width="90%" style="margin-top: -0.3em" data-id="stack-examples" src="../fosdem2022/images/stack_examples_4.svg"/>
    </section>
</section>
<section>
    <section data-markdown data-auto-animate data-timing="30">
        {% markdown %}
            ## Data Processing
        {% endmarkdown %}
        <img height="80%" src="../fosdem2022/images/dataprocessing.svg" class="logo">
        <aside class="notes">
        The data that we process in our process network is an important aspect of the core of OpenHPS.
        We have knowledge, raw data and processed data. Knowledge is everything that we know - such as sensors, radio transmitters
        or building layouts. Raw data is unprocessed data that we want to process, such as individual video or image frames, unfiltered
        accelerometer data. And finally, we have the processed data that will eventually become knowledge.
        </aside>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## DataObject
            
        {% endmarkdown %}
        <div class="row">
            <div class="col-4">
                <img width="100%" style="margin-top: 1em" src="../fosdem2022/images/dataobject.svg">
            </div>
            <div class="col-8">
            {% markdown %}
                ```ts
                // Data object for the person we are tracking
                const me = new DataObject("mvdewync@vub.be");
                me.displayName = "Maxim Van de Wynckel";

                // Phone belonging to the person
                const phone = new DataObject()
                phone.displayName = "Maxim's Phone";
                phone.setParent(me);

                // Watch belonging to the person
                const watch = new DataObject();
                watch.displayName = "Maxim's Android Watch";
                watch.setParent(me);

                // IP camera identified by MAC
                const camera = new CameraObject("80:bb:7c:37:0e:02");
                camera.width = 1980;
                camera.height = 1024;
                camera.fps = 30;
                camera.setPosition(/* ... */);
                ```
            {% endmarkdown %}
            </div>
        </div>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## DataObject
            
        {% endmarkdown %}
        <div class="row">
            <div class="col-4">
                <img width="100%" style="margin-top: 1em" src="../fosdem2022/images/dataobject.svg">
            </div>
            <div class="col-8">
            {% markdown %}
                ```ts {0-2}
                // Data object for the person we are tracking
                const me = new DataObject("mvdewync@vub.be");
                me.displayName = "Maxim Van de Wynckel";

                // Phone belonging to the person
                const phone = new DataObject();
                phone.displayName = "Maxim's Phone";
                phone.setParent(me);

                // Watch belonging to the person
                const watch = new DataObject();
                watch.displayName = "Maxim's Android Watch";
                watch.setParent(me);

                // IP camera identified by MAC
                const camera = new CameraObject("80:bb:7c:37:0e:02");
                camera.width = 1980;
                camera.height = 1024;
                camera.fps = 30;
                camera.setPosition(/* ... */);
                ```
            {% endmarkdown %}
            </div>
        </div>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## DataObject
            
        {% endmarkdown %}
        <div class="row">
            <div class="col-4">
                <img width="100%" style="margin-top: 1em" src="../fosdem2022/images/dataobject.svg">
            </div>
            <div class="col-8">
            {% markdown %}
                ```ts {4-12}
                // Data object for the person we are tracking
                const me = new DataObject("mvdewync@vub.be");
                me.displayName = "Maxim Van de Wynckel";

                // Phone belonging to the person
                const phone = new DataObject();
                phone.displayName = "Maxim's Phone";
                phone.setParent(me);

                // Watch belonging to the person
                const watch = new DataObject();
                watch.displayName = "Maxim's Android Watch";
                watch.setParent(me);

                // IP camera identified by MAC
                const camera = new CameraObject("80:bb:7c:37:0e:02");
                camera.width = 1980;
                camera.height = 1024;
                camera.fps = 30;
                camera.setPosition(/* ... */);
                ```
            {% endmarkdown %}
            </div>
        </div>
    </section>
    <section data-markdown data-auto-animate data-timing="40">
        {% markdown %}
            ## DataObject
            
        {% endmarkdown %}
        <div class="row">
            <div class="col-4">
                <img width="100%" style="margin-top: 1em" src="../fosdem2022/images/dataobject.svg">
            </div>
            <div class="col-8">
            {% markdown %}
                ```ts {14-19}
                // Data object for the person we are tracking
                const me = new DataObject("mvdewync@vub.be");
                me.displayName = "Maxim Van de Wynckel";

                // Phone belonging to the person
                const phone = new DataObject();
                phone.displayName = "Maxim's Phone";
                phone.setParent(me);

                // Watch belonging to the person
                const watch = new DataObject();
                watch.displayName = "Maxim's Android Watch";
                watch.setParent(me);

                // IP camera identified by MAC
                const camera = new CameraObject("80:bb:7c:37:0e:02");
                camera.width = 1980;
                camera.height = 1024;
                camera.fps = 30;
                camera.setPosition(/* ... */);
                ```
            {% endmarkdown %}
            </div>
        </div>
    </section>
    <section data-markdown data-auto-animate data-timing="30">
        {% markdown %}
            ## Absolute and Relative Positions
        {% endmarkdown %}
        <div class="row">
            <div class="col-5">
                {% markdown %}
                    **Absolute**
                    - 2D, 3D, geographical, ...
                    - Within a reference space

                    **Relative**
                    - Distance, angle, velocity, ...
                    - Relative to another *object*
                {% endmarkdown %}
            </div>
            <div class="col-7">
            {% markdown %}
                ```ts
                // Absolute geographical position
                me.setPosition(new GeographicalPosition(
                    50.8204, 4.3921
                ));

                // Relative position(s) to another object
                me.addRelativePosition(new RelativeDistance(
                    "9F:F1:90:4C:F5:6A", 5.2, LengthUnit.METER
                ));
                me.addRelativePosition(new RelativeDistance(
                    "DC:0F:14:B2:6B:80", 1.4, LengthUnit.METER
                ));
                ```
            {% endmarkdown %}
            </div>
        </div>
        <img src="../fosdem2022/images/position.svg" width="50%">
    </section>
</section>

<section>
   <section data-markdown data-auto-animate data-timing="80">
        <h2 data-id="title-dataframe">DataFrame</h2>
        <div class="row">
            <div class="col-4">
                <img width="100%" src="../fosdem2022/images/dataframe.svg"/>
            </div>
            <div class="col-8">
            {% markdown %}
                ```ts
                // Sensor that captured the frame
                const camera = new CameraObject();

                // Create a new frame
                const frame = new VideoFrame();
                frame.source = camera;
                frame.image = myImage;

                // Add detected objects to frame
                frame.addObject(/* ... */);
                frame.addObject(/* ... */);
                frame.addObject(/* ... */);
                ```
            {% endmarkdown %}
            </div>
        </div>
        <img width="50%" src="../fosdem2022/images/dataframe2.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="0">
        <h2 data-id="title-dataframe">DataFrame ...</h2>
        {% markdown %}
            ### Pushing Data

        {% endmarkdown %}
        <img width="100%" src="../ipin2021/images/nodes-push.svg"/>
    </section>
    <section data-markdown data-auto-animate data-timing="0">
        <h2 data-id="title-dataframe">DataFrame ...</h2>
        {% markdown %}
            ### Pulling Data

        {% endmarkdown %}
        <img width="100%" src="../ipin2021/images/nodes-pull.svg"/>
    </section>
</section>

<section>
    <section data-markdown data-auto-animate data-timing="0">
        {% markdown %}
            ## Positioning Model
        {% endmarkdown %}
        <div class="row">
            <div class="col-12">
            {% markdown %}
                ```ts
                ModelBuilder.create()
                    .from(new CallbackSourceNode(() => {
                        const myObject = new DataObject("mvdewync");
                        const frame = new DataFrame();
                        frame.addObject(myObject);
                        return frame;
                    }))
                    .via(new CallbackNode((frame: DataFrame) => { /* ... */ }))
                    .to(new CallbackSinkNode((frame: DataFrame) => { /* ... */ }))
                    .build().then((model: Model) => { /* ... */ });
                ```
            {% endmarkdown %}
            </div>
        </div>
        <img src="../fosdem2022/images/positioningmodel.svg" width="70%">
    </section>
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Exercises Dataset
    {% endmarkdown %}
    <iframe width="100%" height="80%" frameborder="0" src="https://observablehq.com/embed/@openhps/openhps-fingerprinting-dataset-overview?cell=*"></iframe>
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Exercise 1 - Multilateration
        ### Question 1
        > Create a new Bluetooth beacon object with the ID column as its uid 
        and an absolute 3d position for the X, Y and Z coordinates.
        Return the beacon object in this function.

        ### Question 2
        > Create a relative position for the rssi and beacon
        Use the RelativeRSSI class in combination with a new BLEObject that uses the beacon name as its UID
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Exercise 1 ...
        ### Question 3
        > Convert the RSSI to a distance using log distance propagation
        Assume we have a calibrated received signal strength of -69 at 1 meter distance.
        Play around with the environment factor to see what works best.

        ### Question 4
        > Use the RSSI converted to a distance (from question 2) to
        calculate the position with multilateration.
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Exercise 2 - Fingerprinting
        ### Question 1
        > Create a fingerprint service that will store the scene analysis.
        Experiment with the default RSSI value and grouping

        ### Question 2
        > Create a KNN fingerprinting node to convert sensor data to a position.
        Experiment with the parameters to obtain a better result.
    {% endmarkdown %}
</section>
<section data-markdown class="left">
    {% markdown %}
        ## Exercise 3 - Location Awareness
        ### Question 1
        > Load the spaces/features defined in our dataset (spaces.geo.json).
        The file is already loaded as the variable GEOJSON_FEATURES.

        ### Question 2
        > Emit the event of entering and exiting a space
        This event should only trigger when you enter a new space.
        The 'enterspace' event should only trigger when you enter a new space.
        The 'exitspace' event should only trigger when you leave a space.
    {% endmarkdown %}
</section>